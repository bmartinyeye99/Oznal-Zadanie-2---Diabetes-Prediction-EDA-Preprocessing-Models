---
title: "zadanie_2_Branny_Bopko"
output: html_document
date: "2024-04-13"
---

# Dataset o Diabete

-   **Diabetes_binary**: máte diabetes? 0 = no diabetes 1 = pre-diabetes 2 = diabetes
-   **HighBP**: Dospelí, ktorým lekár, sestra alebo iný zdravotnícky pracovník povedal, že majú vysoký krvný tlak (0,1)
-   **HighChol**: Boli vám KEDYKOĽVEK povedané lekárom, sestrou alebo iným zdravotníckym pracovníkom, že máte vysoký cholesterol? (0,1)
-   **CholCheck**: Kontrola cholesterolu v posledných piatich rokoch (0,1)
-   **BMI**: Index telesnej hmotnosti (BMI)
-   **Smoker**: Fajčili ste počas celého života aspoň 100 cigariet? [Poznámka: 5 balíčkov = 100 cigariet] (0,1)
-   **Stroke**: (Bolo vám povedané) že ste mali mozgovú príhodu. (0,1)
-   **HeartDiseaseorAttack**: Respondenti, ktorí kedy uviedli, že majú koronárnu srdcovú chorobu (CHD) alebo infarkt myokardu (MI) (0,1)
-   **PhysActivity**: Dospelí, ktorí uviedli, že počas posledných 30 dní robili fyzickú aktivitu alebo cvičenie okrem svojej pravidelnej práce (0,1)
-   **Fruits**: Konzumácia ovocia 1 alebo viackrát denne (0,1)
-   **Veggies**: Konzumácia zeleniny 1 alebo viackrát denne (0,1)
-   **HvyAlcoholConsump**: Veľkí konzumenti alkoholu (dospelí muži, ktorí konzumujú viac ako 14 nápojov týždenne a dospelé ženy, ktoré konzumujú viac ako 7 nápojov týždenne)(0,1)
-   **AnyHealthcare**: Máte nejaké zdravotné poistenie vrátane zdravotného poistenia, predplatených plánov ako HMO, alebo vládnych plánov ako Medicare, alebo Indian Health Service? (0,1)
-   **NoDocbcCost**: Bol v posledných 12 mesiacoch čas, keď ste potrebovali vidieť lekára, ale nemohli ste si to dovoliť kvôli nákladom? (0,1)
-   **GenHlth**: Povedali by ste, že vo všeobecnosti je váš zdravotný stav: hodnotenie (1 \~ 5)
-   **MentHlth**: Teraz, keď premýšľate o svojom duševnom zdraví, ktoré zahŕňa stres, depresiu a problémy s emóciami, koľko dní počas posledných 30 dní bolo vaše duševné zdravie nie dobré? (0 \~ 30)
-   **PhysHlth**: Teraz, keď premýšľate o svojom fyzickom zdraví, ktoré zahŕňa fyzické choroby a zranenia, koľko dní počas posledných 30 dní bolo vaše fyzické zdravie nie dobré? (0 \~ 30)
-   **DiffWalk**: Máte vážne ťažkosti s chôdzou alebo s vyliezaním schodov? (0,1)
-   **Sex**: Uveďte pohlavie respondenta (0,1) (Žena alebo Muž)
-   **Age**: Štrnásťstupňová veková kategória (1 \~ 14)
-   **Education**: Aký je najvyšší stupeň alebo rok školy, ktorý ste dokončili? (1 \~ 6)
-   **Income**: Je váš ročný domáci príjem zo všetkých zdrojov: (Ak respondent odmietne pri akejkoľvek úrovni príjmu, označte "Refused") (1 \~ 8)

```{r}
library(leaps)
library(pROC)
library(reshape2)
library(tidyverse)
library(magrittr) 
library(data.table) 
library(caret)
library(ggplot2)
library(e1071)
library(readxl)
library(cowplot)
library(patchwork)
library(polycor)
library(psych)
library(caret)
library(caretEnsemble)
library(glmnet)
```

Nastavenie cesty

```{r}
setwd("./") 
list.files() 
```

## Načítanie datasetu

```{r}
data <- read.csv("diabetes_012_health_indicators_BRFSS2015.csv")
names(data)
head(data)
```

# Popis dát

```{r}
summary(data)
cat("Colnum : ", ncol(data),"\n")
cat("Rownum : ",nrow(data))
```

```{r}
View(data)
```

## Unikátne hodnoty 

```{r}
number_of_uniq_data <- sapply(data, function(x) length(unique(x)))
number_of_uniq_data
```
## Unikátne hodnoty diabetu
0 = no diabetes 1 = pre-diabetes 2 = diabetes


```{r}
table(data$Diabetes_012, useNA = 'always')
```
Vidíme, že máme veľa binárnych hodnôt. Hodnoty, ktorými budeme pracovať pri vytáraní modelu budeme musieť enkódovať. Naša predikovaná hodnota Diabetes_012 disponuje 3 hodnotami. 0 - no diabetes 1 - prediabetes 2 - diabetes. 

```{r}
sapply(data, class)
table(sapply(data, class))
sum(is.na(data))

```

Okrem toho dataset obsahuje všetky pozorovania v numerických hodnotách a nemá chýbajúce hodnoty.

```{r}
cat("Number of rows: ", nrow(data),"\n")
cat("Number of duplicates ")
num_duplicates <- sum(duplicated(data))
print(num_duplicates)

# Remove duplicated rows
data <- data[!duplicated(data), ]

# Get the number of rows after deletion of duplicates
cat("Number of rows: ", nrow(data),"\n")

```

Po odstránení duplikátov nám ostalo 229781 pozorovaní. 

```{r}
data <- data %>% 
  mutate(
    Diabetes = case_when(
      Diabetes_012 %in% c(1, 2) ~ 1,
      Diabetes_012 == 0 ~ 0
    )
  ) %>%
  select(-Diabetes_012)
```



```{r}
print("Diabetes values :")
table(data$Diabetes, useNA = 'always')
```

Kedže dataset nám opisuje multi-class problém (máme 3 triedy v Diabetes_012), stav prediabetu a diabetu zakódujeme do hodnoty 1. 
Náš model teda bude riešiť two-class problém pri klasifikácii. Stav 0 sme nechali 0. (No diabetes)

```{r}

numeric_columns <- sapply(data, is.numeric)  # Identify numeric columns
non_binary_numeric_columns <- numeric_columns & !apply(data, 2, function(x) all(x %in% c(0, 1)))
nonbinarycolumns <- names(non_binary_numeric_columns[non_binary_numeric_columns])

print_histograms <- function(data, columns) {
  for (col_name in columns) {
    
    if (col_name == "BMI"){
      p <- ggplot(data, aes(x = BMI)) + 
      geom_histogram(fill = "skyblue", color = "black") +
      ggtitle("Distribution of BMI") + 
      xlab("BMI") + 
      ylab("Count")
        print(p)
    }
    else{
    data[[col_name]] <- factor(data[[col_name]])
    p <- ggplot(data, aes_string(x = col_name)) +
      geom_bar(fill = "skyblue", color = "black") +
      scale_x_discrete(drop = FALSE) +  # Ensure all unique values are shown on x-axis
      theme_minimal() +
      ggtitle(paste("Distribution of", col_name)) +
      xlab(col_name) +
      ylab("Count")
    print(p)
    }
  }
}

print_histograms(data, nonbinarycolumns)

```

Čo sa týka viachodnotových stĺpcov v datasete, vidíme že normálne distribuovaným hodnotám sa približujú hodnoty v Age. Hodnota BMI sa takito približuje k normálnemu distribuovaniu no vidíme tu pravé zošikmenie hodnôt ( right skew/positive skew ) 

```{r}

# Define the columns of interest
columns_of_interest <- c('BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income')

# Create a list to store individual boxplot plots
plots <- list()

# Loop through each column and create a boxplot
for (i in 1:length(columns_of_interest)) {
  col <- columns_of_interest[i]
  p <- ggplot(data, aes_string(x = col)) +
    geom_boxplot(fill = "skyblue", color = "black") +
    ggtitle(paste("Distribution of", col)) +
    theme_minimal(base_size = 8) +  # Set base font size
    theme(axis.text.x = element_text(size = 6),  # Set x-axis text size
          axis.text.y = element_text(size = 6)) +  # Set y-axis text size
    xlab(col) +
    ylab("Value")
  plots <- c(plots, list(p))  # Append each plot to the list
}

# Combine plots into a single plot grid
combined_plot <- cowplot::plot_grid(plotlist = plots, nrow = 4, ncol = 2)

# Adjust the size of the combined plot
ggsave("combined_plot.png", combined_plot, width = 10, height = 10)

# Print the combined plot
print(combined_plot)

```

Boxploty takisto potvrdzujú, že najbližšie k normálnej distribúcii je stĺpec Age. 

```{r}
handle_outliers <- function(data, columns, sensitivity) {
  na_counts <- setNames(numeric(length(columns)), columns)  # Initialize a vector to hold NA counts for each column
  totalNumOfOutliers = 0
  for (col in columns) {
    # Count NAs before handling outliers
    na_count_before <- sum(is.na(data[[col]]))
    
    # Calculate quartiles and IQR
    q1 <- quantile(data[[col]], 0.25, na.rm = TRUE)
    q3 <- quantile(data[[col]], 0.75, na.rm = TRUE)
    iqr <- q3 - q1
    
    # Define upper and lower bounds for outliers
    upper_bound <- q3 + iqr*sensitivity
    lower_bound <- q1 - iqr*sensitivity
    
    print(paste("Upper bound for", col, ":", upper_bound))
    print(paste("Lower bound for", col, ":", lower_bound))
    # Replace outliers with NA
    data[[col]] <- ifelse(data[[col]] < lower_bound | data[[col]] > upper_bound, NA, data[[col]])
    
    # Count NAs after handling outliers
    na_count_after <- sum(is.na(data[[col]]))
    
    # Calculate the number of NAs added
    na_counts[col] <- na_count_after - na_count_before
    totalNumOfOutliers = totalNumOfOutliers + na_counts
    # Print the number of NAs added for the current column
    cat("NAs added in", col, ":", na_counts[col], "\n")
  }
      data <- na.omit(data)
  cat("Total number of outliers detected : ", totalNumOfOutliers)
  # Return the cleaned data and the NA counts
  return(data)
}
```

```{r}
# Function returns names of non binary columns
non_binary_columns <- function(data) {
  non_binary_cols <- character(0)  # Initialize an empty vector to store non-binary column names
  for (col in names(data)) {
    unique_vals <- unique(data[[col]])
    if (length(unique_vals) > 2) {
      non_binary_cols <- c(non_binary_cols, col)  # Add column name to the list of non-binary columns
    }
  }
  return(non_binary_cols)
}

# Usage:
nonbinarycolumns <- non_binary_columns(data)
nonbinarycolumns <- non_binary_columns(data)
cat("Non binary columns : ",nonbinarycolumns)

#data_With_Outliers <- data
#data <- handle_outliers(data, nonbinarycolumns, 0.8)
#head(data)
```

Nebudeme v našom prípade odstranovať outliers lebo tie nesú dôležitú informáciu pre ako BMI tak aj samotný diabetes.

```{r}
library(ggplot2)
library(reshape2)

# Function to generate heatmap for correlation matrix
generate_correlation_heatmap <- function(correlation_matrix, title) {
  numsize = 1.9
  if ( title == "Correlation of Features - Non-Binary Columns")
    numsize = 2.5
  else
    numsize = 1.9
  # Convert correlation matrix to dataframe
  correlation_df <- as.data.frame(correlation_matrix)
  correlation_df$row <- rownames(correlation_matrix)

  # Melt dataframe to long format
  correlation_df_long <- melt(correlation_df, id.vars = "row")

  # Set the size of the plot
  options(repr.plot.width = 10, repr.plot.height = 8)

  # Plot heatmap
  ggplot(data = correlation_df_long, aes(x = row, y = variable, fill = value)) +
    geom_tile(color = "white") +
    geom_text(aes(label = round(value, 2)), color = "black", size = numsize) +
    scale_fill_gradient2(low = "blue", high = "red", na.value = "white", limits = c(-1, 1), name = "Correlation") +
    theme_minimal() +
    labs(title = title) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels
}

# Compute correlation matrix for the entire dataset
correlation_matrix <- cor(data)

# Compute correlation matrix for non-binary columns
correlation_matrix_nonbinary <- cor(data[, nonbinarycolumns])

# Generate heatmap for non-binary columns
generate_correlation_heatmap(correlation_matrix_nonbinary, "Correlation of Features - Non-Binary Columns")

```

Na grafe je vidno, že viacere hodnoty sa korelujú. Dokonca máme aj negatívne korlácie. Z tychto hodnot nedozvieme vsetko, ale napr. mozeme mat predpoklad, ze cim vzdelanejši je clovek, tym viac zaraba, alebo cim viac zaraba clovek, tym ma vacsie vzdelanie.

Klucove info z tejto tabulky su napr:, age, GenHlth, BMI, MentlHlth, PhysHlth

Vypocitame korelácie medzi kategorickými hodnotami, ktoré rozdelujeme na nominalne a ordinalne.

```{r}
ordinal_categorical_columns <- c("Education", "Income", "GenHlth")

binary_cols <- c('HighBP', 'HighChol', 'CholCheck', 'Smoker',
          'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Veggies',
          'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'DiffWalk', 'Diabetes')

all_categorical_values <-c('HighBP', 'HighChol', 'CholCheck', 'Smoker',
          'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Veggies',
          'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'DiffWalk', 'Diabetes', "Education", "Income", "GenHlth")

binary_data <- data[, binary_cols]
ordinal_data <- data[, ordinal_categorical_columns]

# Calculate Tetrachoric correlation for binary columns
tetrachoric_corr <- tetrachoric(binary_data)

# Print the results
print("Tetrachoric Correlation for Binary Columns:")
print(tetrachoric_corr)

```

Vypocitali sme korelacie medzi nominalnymi kategorickými hodnotami. Tieto výsledky nám pomozu vytvorit model, kedze vidíme vztahy medzi hodnotou Diabetes co chceme predikovat, a ostatnými hodnotami. Napr. HighBP a Diabetes maju mierne velku korelcáie, preto si predpokladáme, že vyssi krvný tlak a srdcové ochorenia znamenaju vacsiu sancu na diabetes.

Na druhej strane, fyzická aktivita, konzumovanie zelenín a absolvovanie preventívnych návštev lekára - čiže keď sa nenastala taká situácia, že doktor nebol navštevovaný, ked by mal byt - NoDocbcCost, znižujú šancu Diabetes. Prekvapivo aj konzumácia alkoholu.

Klucove info: HighBP, HighChl, Chlch, HrtDa,, HvyAc, Stroke, AnyHL

```{r}
# Calculate Polychoric correlation for ordinal columns
polychoric_corr <- polychoric(ordinal_data)

print("###########")

print("Polychoric Correlation for Ordinal Columns:")
print(polychoric_corr)
```

```{r}
print(nonbinarycolumns)
plots <- list()

all_categorical_values_without_diabetes <-c('HighBP', 'HighChol', 'CholCheck', 'Smoker',
          'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Veggies',
          'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'DiffWalk', "Education", "Income", "GenHlth")
# Create stacked barplots for categorical values and Diabetes
for (col in all_categorical_values_without_diabetes) {
  
  # Create bar plot
  plot <- data %>%
    mutate(Diabetes = factor(Diabetes)) %>% # Convert Diabetes to factor
    group_by(Diabetes, !!sym(col)) %>%
    summarise(Count = n()) %>%
    ggplot(aes(fill = Diabetes, y = Count, x = !!sym(col))) + 
    geom_bar(position = 'stack', stat = 'identity') +
    theme_minimal() + 
    labs(x = col, y = "Count", title = paste("Distribution of Diabetes in ", col)) +
    theme(plot.title = element_text(hjust = 0.5, size = 12, face = 'bold')) +
    scale_fill_manual('Diabetes', values = c('lightblue', 'coral'))
  
  
   # Store the plot
   plots[[col]] <- plot
 }

 # Print the plots
 for (i in seq_along(plots)) {
  #print(plots[[i]])
 }
```

Na tychto grafoch vidíme ditribúciu Diabetes medzi ostatnými binárnými hodnotami. Očividne sú viac diabetikov medzi jednotlivcami, ktorí maju vysoky cholesterol, krvný tlak, alebo medzi tými ktorí uz mali stroke

```{r}

diabetes_percentage <- data %>%
  group_by(Diabetes) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = prop.table(Count) * 100)

# Create pie chart
piechart <- ggplot(diabetes_percentage, aes(x = "", y = Percentage, fill = factor(Diabetes))) +
  geom_bar(stat = "identity", width = 1) +
  geom_text(aes(label = paste(round(Percentage, 1), "%")), position = position_stack(vjust = 0.5)) +  # Add percentage labels
  coord_polar(theta = "y") +
  labs(fill = "Diabetes", title = "Percentage Distribution of Diabetes") +
  theme_void() +
  theme(legend.position = "bottom")  # Move legend to the bottom

# Print pie chart
print(piechart)
```

Okrem korelácie, pouzivame regsubsets aby sme nasli najlepsie predictory pre BMI

```{r}
# Perform best subset regression
Best_Subset <- regsubsets(BMI ~ .,
                          data = data,
                          nbest = 1,      # 1 best model for each number of predictors
                          nvmax = NULL,   # NULL for no limit on number of variables
                          force.in = NULL, force.out = NULL,
                          method = "exhaustive")

# Summarize the results
summary_best_subset <- summary(Best_Subset)

# View the summary output
summary_best_subset
which.max(summary_best_subset$adjr2)
summary_best_subset$which[21,]
```

<!-- Hviezdičky ( * ) v dolnej časti výstupu označujú, ktoré predikčné premenné patria do najlepšieho regresného modelu pre každý možný model s rôznym počtom predikčných premenných. -->

<!-- Pre model s jednou prediktorovou premennou je najlepším regresným modelom model, v ktorom sa ako prediktorová premenná použije HighBP -->

<!-- V prípade modelu s dvoma prediktorovými premennými sa najlepší regresný model vytvorí použitím Diabetes a HighBP ako prediktorových premenných. -->

# Linear regression model

```{r}
model <- data %$% 
  lm(BMI ~ Age + GenHlth + HighBP + Diabetes + Sex )

summary(model)
```

Celkovo model naznačuje, že Age, General Health, High Blood Pressure, Diabetes, and Sex sú významnými prediktormi BMI. Model však vysvetľuje len malú časť rozptylu BMI (adjusted R-squared = 0.07293), čo naznačuje, že BMI môžu ovplyvňovať aj iné faktory, ktoré nie sú zahrnuté v modeli.

Intercept: Priemerná hodnota BMI, keď sú všetky ostatné premenné nulové, je 26.70. Tento koeficient je štatisticky významný (p \< 0.05).

-   Age: Za každú jednotku zvýšenia veku (Age) sa BMI zníži o -0.19, čo je štatisticky významné (p \< 0.05). Aj keď vplyv malý, je považovaný za štatisticky signifikantný.

Ak má osoba vysoký krvný tlak (HighBP = 1), očakáva sa, že jej BMI bude v priemere vyšší približne o 1,337023 jednotky v porovnaní s osobou bez vysokého krvného tlaku (HighBP = 0), pričom sa kontrolujú ostatné premenné v modeli.

Plottig reg lines for predictors

```{r}
ggplotRegression <- function(fit) {
  require(ggplot2)
  
  predictors <- names(fit$model)[-1]  # Exclude the response variable
  
  plots <- list()
  
  for (predictor in predictors) {
    plot <- ggplot(fit$model, aes_string(x = predictor, y = names(fit$model)[1])) + 
      geom_point() +
      stat_smooth(method = "lm", col = "red") +
      labs(title = paste("Adj R2 =", signif(summary(fit)$adj.r.squared, 5),
                         "Intercept =", signif(coef(fit)[1], 5),
                         "Slope =", signif(coef(fit)[predictor], 5),
                         "P =", signif(summary(fit)$coef[which(rownames(summary(fit)$coef) == predictor), "Pr(>|t|)"], 5)))
    
    plots[[predictor]] <- plot
  }
  
  return(plots)
}

plots <- ggplotRegression(model)

for (predictor in names(plots)) {
  print(plots[[predictor]])
}

```
## Logistická regresia


Budeme klasifikovať s týmto modelom, to či človek nemá diabetes/prediabetes, alebo či sa nachádzav diabetes štádiu. Pôjde teda o binárnu klasifikáciu.

```{r}
# Generate heatmap for entire dataset
generate_correlation_heatmap(correlation_matrix, "Correlation of Features - Entire Dataset")
```
Na základe korelačnej heatmapy vidíme, použijeme predikáty ako HighBP, BMI, GenHlth( ten má silnú koreláciu s DiffWalk a teda toto nepoužijeme kedže vyzerá ze sú vzájomne závislé) a Age. 


```{r}
plot_logistic_regression <- function(data, predictors) {
  for (predictor in predictors) {
    # Plot
    p <- data %>%
      ggplot(aes_string(x = predictor, y = "Diabetes")) +
      geom_point(position = position_jitter(width = 0.3, height = 0.06), 
                 alpha = 0.05, 
                 shape = 1, 
                 size = 1.5) + 
      stat_smooth(method = "glm", method.args = list(family = "binomial"), 
                  aes(color = predictor)) +
      ggtitle(paste("Diabetes vs", predictor), 
              subtitle = "Visualization of logistic regression fit") +
      theme_minimal() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1))
    
    print(p)
  }
}



predictors <- c("HighBP", "PhysActivity", 
                "DiffWalk", "GenHlth", "BMI", "HighBP", 
                "HighChol", "HeartDiseaseorAttack", "Age", "Income")



#plot_logistic_regression(data, predictors)
```

```{r}
model <- glm(Diabetes ~ HighBP + DiffWalk + GenHlth + BMI + Age,
  data = data,
  family = binomial)
summary(model)
```

Zadefinujeme si naše H0

1.H0: Nie je pravda, že človek s diagnostikovaným vysokým krvným tlakom má šancu na diabetes alebo prediabetes.

2.H0: Človek s problémom s chodením nemá diabetes alebo prediabetes.

3.H0: Človek ktorý uviedol, že sa má dobre nemá nemá diabetes alebo prediabetes.

4.H0: BMI nemá vplyv na diabets alebo prediabetes stav.

5.H0: So zvýšeným vekom nestúpa šanca na prediabetes alebo diabetes.


Všetky h0 zamietnuté.


```{r}
real.classes <- model$y
head(model$y, n=10)

predicted.class.probabilities <- model$fitted.values
predicted.classes <- if_else(predicted.class.probabilities >=0.5, 1, 0) 

prediction_vs_real <- data.frame(
  Real.Classes = real.classes,
  Predicted.Class.Probabilities = predicted.class.probabilities,
  Predicted.Classes = predicted.classes
)
```


```{r}
library(caret)
caret::confusionMatrix(as_factor(predicted.classes), as_factor(real.classes), positive = "1")
```
```{r}

TP <- sum(prediction_vs_real$Real.Classes == 1 & prediction_vs_real$Predicted.Classes == 1)
TN <- sum(prediction_vs_real$Real.Classes == 0 & prediction_vs_real$Predicted.Classes == 0)
FP <- sum(prediction_vs_real$Real.Classes == 0 & prediction_vs_real$Predicted.Classes == 1)
FN <- sum(prediction_vs_real$Real.Classes == 1 & prediction_vs_real$Predicted.Classes == 0)

cat("True Positives (TP):", TP, "\n")
cat("True Negatives (TN):", TN, "\n")
cat("False Positives (FP):", FP, "\n")
cat("False Negatives (FN):", FN, "\n")

accuracy <- (TP + TN)/(TP+TN+FN+FP)
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
f1_score <- 2 * (precision * recall) / (precision + recall)

paste("Accuracy score is ", accuracy)
paste("Precision score is ", precision)
paste("Recall score is ", recall)
paste("F1 score is ", f1_score)
```
Model performance pri 0.5 cutoffe je nič moc, podme nájsť optimálny cutoff.

### ROC CURVE

```{r}

roc_obj <- roc(response = real.classes, 
               predictor = predicted.class.probabilities,
               levels = c(0, 1))
```
```{r}
plot(roc_obj, main = "ROC Curve")
abline(a = 0, b = 1, lty = 2, col = "gray")
```

```{r}
coords <- coords(roc_obj, "best", best.method = "youden")
optimal_cutoff <- coords$threshold
optimal_sensitivity <- coords$sensitivity
optimal_specificity <- coords$specificity
```

```{r}
plot(roc_obj)
points(coords$specificity, coords$sensitivity, pch = 19, col = 'red', cex = 0.7)
legend("bottomright", pch = 19, col = 'red', legend = paste("Optimal cutoff:", round(optimal_cutoff, 4)))
optimal_cutoff

```
```{r}
real.classes <- model$y
head(model$y, n=10)

predicted.class.probabilities <- model$fitted.values
predicted.classes <- ifelse(predicted.class.probabilities >=0.1563, 1, 0) 

caret::confusionMatrix(as_factor(predicted.classes), as_factor(real.classes), positive = "1")
```
Model je teda schopnejší správne predikovať s týmto cutoffom aj minoritnú triedu (1 - mám diabetes), vďaka nevybalancovaným triedam ale vidíme, že by sme pre hypochondrov radšej zvolili model s cutoffom 0.5, aby sme im s vačšiou pravdepodobnosťou mohli zaručiť, že nemajú diabetes. Ak by ale bolo podstatné určiť a dôležitejšie určit TRUE POSITIVES, teda správne identifikovať diabetikov, zvolený cutoff je najlepší možný.



## Support vector machine
```{r}
minority_size <- table(data$Diabetes)[2]
```


```{r}
data_minority <- data[data$Diabetes == 1, ] # Minoritná trieda
data_majority <- data[data$Diabetes == 0, ]
data_majority_sampled <- data_majority[sample(nrow(data_majority), minority_size), ]

# Zlúčenie dát späť do vyváženého datasetu
data_balanced <- rbind(data_minority, data_majority_sampled)
head(data_balanced)


```


```{r}
diabetes_percentage <- data_balanced %>%
  group_by(Diabetes) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = prop.table(Count) * 100)

# Create pie chart
piechart <- ggplot(diabetes_percentage, aes(x = "", y = Percentage, fill = factor(Diabetes))) +
  geom_bar(stat = "identity", width = 1) +
  geom_text(aes(label = paste(round(Percentage, 1), "%")), position = position_stack(vjust = 0.5)) +  # Add percentage labels
  coord_polar(theta = "y") +
  labs(fill = "Diabetes", title = "Percentage Distribution of Diabetes") +
  theme_void() +
  theme(legend.position = "bottom")  # Move legend to the bottom

# Print pie chart
print(piechart)
```


```{r}
correlation_matrix <- cor(data_balanced)
correlations_with_diabetes <- abs(correlation_matrix["Diabetes", ])
correlations_with_diabetes <- correlations_with_diabetes[-which(names(correlations_with_diabetes) == "Diabetes")]
correlations_with_diabetes

```
Zvolenie features, ktoré korelujú s Diabetom aspon na 0.2

```{r}
threshold <- 0.2
selected_features <- names(which(correlations_with_diabetes >= threshold))

formula <- as.formula(paste("Diabetes ~", paste(selected_features, collapse = " + ")))

selected_features

```

### Tréning modelu

```{r}
n_samples <- 100
random_indices <- sample(nrow(data_balanced), n_samples, replace = FALSE)
random_samples <- data_balanced[random_indices, ]




hyperparameters <- expand.grid(
                    .method = c("svmLinear", "svmRadialSigma", "svmPoly")
                   )

ctrl <- trainControl(method = "cv",  # cross-validation
                     number = 10,     # 10-fold CV
                     classProbs = TRUE,
                     summaryFunction = twoClassSummary,  
                     savePredictions = TRUE)  # vypisy cez trening

for (method in hyperparameters$.method) {
  if (method == "svmRadialSigma") {
    svm_model_radial <- train(form = formula,
                       data = random_samples,
                       method = method,
                       trControl = ctrl,
                       tuneGrid = expand.grid(
                         .sigma = seq(0.005, 0.2, length = 3),
                         .C = seq(0.1, 10, length = 3)),
                       metric = "ROC",
                       preProcess = c("center", "scale"))

  } else if (method == "svmPoly") {
    svm_model_poly <- train(form = formula,
                       data = random_samples,
                       method = method,
                       trControl = ctrl,
                       tuneGrid = expand.grid(
                         .degree = seq(2, 5, length = 4),
                         .C = seq(0.1, 10, length = 3),
                         .scale = c(0, 1)),
                       metric = "ROC",
                       preProcess = c("center", "scale"))

  } else {
    svm_model_linear <- train(form = formula,
                       data = random_samples,
                       method = method,
                       trControl = ctrl,
                       tuneGrid = expand.grid(
                         .C = seq(0.1, 10, length = 3)),
                       metric = "ROC",
                       preProcess = c("center", "scale"))

  }
}
```

### Vyhodnotenie modelu
```{r}

```

```{r}
str(svm_model_linear$pred$obs)
str(svm_model_linear$pred$pred)
```




















Defining LASSO model

```{r}
# Define the control using a random forest selection function
control <- rfeControl(functions = rfFuncs, # random forest
                      method = "repeatedcv", # repeated cv
                      repeats = 5, # number of repeats
                      number = 10) # number of folds
```

```{r}
library(randomForest)
```

RFE for feature selection, runs very long - dont know wether we have to use it

```{r}
# # Features
# x <- data %>%
#   select(-BMI) %>%
#   as.data.frame()
# 
# # Target variable
# y <- data$BMI
# 
# # Training: 80%; Test: 20%
# set.seed(2021)
# inTrain <- createDataPartition(y, p = .80, list = FALSE)[,1]
# 
# x_train <- x[inTrain, ]
# x_test  <- x[-inTrain, ]
# 
# y_train <- y[inTrain]
# y_test  <- y[-inTrain]
# 
# # Define resampling control
# control <- rfeControl(functions = rfFuncs, method = "cv", number = 5)
# 
# # Run RFE
# result_rfe1 <- rfe(x = x_train, 
#                    y = y_train, 
#                    sizes = c(1:ncol(x_train)),
#                    rfeControl = control)
# 
# # Print the results
# print(result_rfe1)
# 
# # Print the selected features
# print(predictors(result_rfe1))
# 
# # # Print the results visually
# # ggplot(data = result_rfe1, aes(x = Variables, y = Accuracy)) + geom_point() + theme_bw()
# # ggplot(data = result_rfe1, aes(x = Variables, y = Kappa)) + geom_point() + theme_bw()

```

```{r}
selected_cols <- c("Age", "GenHlth", "HighBP", "Diabetes", "Sex", "BMI")
data_subset <- data[selected_cols]

# Step 3: Split the dataset into features (X) and target variable (BMI)
X <- data_subset[, !(names(data_subset) %in% "BMI")]
y <- data_subset$BMI

# Step 4: Standardize the features
X_scaled <- scale(X)

# Step 5: Perform k-fold cross-validation
set.seed(123)  # Set seed for reproducibility
folds <- createFolds(y, k = 5, list = TRUE)  # Create k folds

# Initialize vectors to store cross-validation results
cv_errors <- c()
cv_lambdas <- c()

for (fold in seq_along(folds)) {
  # Prepare training and testing datasets for the fold
  train_indices <- unlist(folds[setdiff(names(folds), fold)])
  test_indices <- folds[[fold]]
  
  X_train <- X_scaled[train_indices, ]
  y_train <- y[train_indices]
  X_test <- X_scaled[test_indices, ]
  y_test <- y[test_indices]
  
  # Fit LASSO regression model using glmnet
  cv_model <- cv.glmnet(X_train, y_train, alpha = 1, nfolds = 5)
  
  # Extract lambda with minimum cross-validated error
  best_lambda <- cv_model$lambda.min
  
  # Predict on test set
  y_pred <- predict(cv_model, s = best_lambda, newx = X_test)
  
  # Calculate mean squared error (MSE) for the fold
  fold_error <- mean((y_pred - y_test)^2)
  
  # Store cross-validation results
  cv_errors <- c(cv_errors, fold_error)
  cv_lambdas <- c(cv_lambdas, best_lambda)
}

# Step 6: Choose the lambda with the minimum average cross-validated error
best_lambda <- mean(cv_lambdas[which.min(cv_errors)])

# Step 7: Train the final LASSO regression model using the entire dataset
final_model <- glmnet(X_scaled, y, alpha = 1)
final_model_with_lambda <- glmnet(X_scaled, y, alpha = 1, lambda = best_lambda)


y_pred_final <- predict(final_model_with_lambda, s = best_lambda, newx = X_scaled)
final_rmse <- sqrt(mean((y_pred_final - y)^2))
final_rmse
# treba implementovat este R squared
plot(cv_model)
```

Dostali sme skoro rovnake vysledky ako s linearnou regresiou. R squared je 0.076 co znamena ze prediktory su zodpovedne za 7.6 % variancie BMI, co je relativne malo.

Priemern8 chyba predikcie a realnej hodnoty je 14.64678., co je vysoke. Takyto rozdiel v BMI vyrazne zmeni stav cloveka.
